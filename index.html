<!DOCTYPE html>
<!-- saved from url=(0047)https://www.cs.dartmouth.edu/~ltx/#publications -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">



<title>Tianxing Li's Website</title>
<link href="./Tianxing Li&#39;s Website_files/bootstrap.css" rel="stylesheet">
<link href="./Tianxing Li&#39;s Website_files/style.css" rel="stylesheet" type="text/css">
<link rel="shortcut icon" href="https://www.cs.dartmouth.edu/~ltx/images/favicon.ico" type="image/vnd.microsoft.icon"></head>

<body>
<div class="navbar navbar-default navbar-fixed-top">
<div class="container">
	
    <a class="navbar-brand" href="https://www.cs.dartmouth.edu/~ltx/#"></a>
	<button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#navbar-main" aria-expanded="false">
    	<span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
    </button>
    
    <div class="navbar-collapse collapse" id="navbar-main">
      <ul class="nav navbar-nav">
        <li><div id="logo"><a href="https://www.cs.dartmouth.edu/~ltx/">Tianxing Li</a></div></li>
      	<li><a href="https://www.cs.dartmouth.edu/~ltx/#publications">Publications</a></li>
      	<li><a href="https://www.cs.dartmouth.edu/~ltx/#research">Research</a></li>
      	<li><a href="https://www.cs.dartmouth.edu/~ltx/resume.pdf">CV</a></li>
      </ul>
   	</div>
    
</div>
</div>

<div id="container">
<!-- header -->
<div id="header">

</div>

<!--end header -->
<!-- main -->
<div id="main">
<div id="sidebar">
<h2><img src="./Tianxing Li&#39;s Website_files/profile.png" width="220" height="215"></h2>
<sidep>CONTACT INFO</sidep>
<ul>
          <p>Email: <a href="mailto:tianxing@cs.dartmouth.edu">tianxing@cs.dartmouth.edu</a></p>
          <p>Address: Lab 151 Sudioff Building, Dartmouth College, NH 03755</p>
          
<a href="https://www.facebook.com/ricky.t.li" target="_blank"><img src="./Tianxing Li&#39;s Website_files/facebook.jpeg" width="25" height="25" alt="Facebook"></a>
                                    <a href="https://www.linkedin.com/pub/tianxing-li/56/ba7/996" target="_blank"><img src="./Tianxing Li&#39;s Website_files/linkedin.jpeg" width="25" height="25" alt="Linkedin"></a>
                                    <a href="https://twitter.com/Tianxing_Li" target="_blank"><img src="./Tianxing Li&#39;s Website_files/twitter.png" width="25" height="25" alt="Twitter"></a>

<ul><p></p>
<sidep>NEWS</sidep>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>June. 24th 2018</strong><br>
	Our paper got accepted by <strong><a href="https://uist.acm.org/uist2018/program">UIST'18</a></strong>
</p><p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>May. 24th 2018</strong><br>
	Our paper got accepted by <strong><a href="https://www.sigmobile.org/mobicom/2018/program.php">MobiCom'18</a></strong>
</p><p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Feb. 7th 2018</strong><br>
	Invited as a TPC member for <strong><a href="https://www.sigmobile.org/mobisys/2018/">PhD forum</a></strong> at MobiSys'18, consider submitting!
</p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Jan. 15th 2018</strong><br>
	Invited as a TPC member for <strong><a href="http://www.cryblock.org/index.html">CRYBLOCK</a></strong> at MobiSys'18, consider submitting!
</p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Nov. 8th 2017</strong><br>
	LiGaze won the <font color="red">Best Paper Nominee</font> at  <strong><a href="http://sensys.acm.org/2017/">Sensys'17</a></strong>
</p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Jul. 17th 2017</strong><br>
	LiGaze got accepted by <strong><a href="http://sensys.acm.org/2017/">Sensys'17</a></strong>
</p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Jun. 27th 2017</strong><br>
	Aili got accepted by <strong><a href="http://ubicomp.org/ubicomp2017/program/program.html">Ubicomp'17</a></strong>
</p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Feb. 10th 2017</strong><br>
	I will be the co-chair for <strong><a href="http://mnslab.org/s3/">S3</a></strong> at MobiCom'17, consider submitting!
</p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Dec. 24th 2016</strong><br>
	I will be the co-chair for <strong><a href="https://www.sigmobile.org/mobisys/2017/workshops/phd/index.htm">PhD forum</a></strong> at MobiSys'17, consider submitting!
</p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>May 6th 2016</strong><br>
	I won the <font color="red">Best Presentation Award</font> at <strong><a href="http://www.cs.dartmouth.edu/~csrs/">CSRS 2016</a></strong>.
</p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Apr. 1st 2016</strong><br>
	Invited as a TPC member for <strong><a href="http://www.sigmobile.org/mobisys/2016/workshops/phd/committee_and_panel.htm">PhD forum</a></strong> at MobiSys'16, consider submitting!
</p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Mar. 20th 2016</strong><br>
	Invited as a TPC member for <strong><a href="http://winlab.rutgers.edu/s3/">S3</a></strong> at MobiCom'16, consider submitting!
</p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Mar. 1st 2016</strong><br>
	Our StarLight got accepted by <strong><a href="http://www.sigmobile.org/mobisys/2016/accepted.php">MobiSys'16</a></strong></p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Sept. 11st 2015</strong><br>
	<strong><a href="http://dartnets.cs.dartmouth.edu/lisense">LiSense</a> </strong>won the <font color="red">Best Video Award</font> at <strong><a href="http://www.sigmobile.org/mobicom/2015/program.html">MobiCom'15</a></strong></p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>July 31st 2015</strong><br>
	<strong><a href="http://dartnets.cs.dartmouth.edu/lisense">LiSense</a> </strong>website and <strong><a href="https://www.youtube.com/watch?v=7wK-zo66GdY">demo video</a> </strong> are up!</p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Jun. 15th 2015</strong><br>
	I won <font color="red">3rd place</font> of <strong><a href="http://neukom.dartmouth.edu/programs/graduate_research_2015.html">Neukom Prize</a></strong> for Outstanding Graduate Research at Dartmouth College</p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Jun. 13th 2015</strong><br>
	HiLight code is released on <strong><a href="https://github.com/Tianxing-Dartmouth/HiLight">Github</a></strong></p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Jun. 4th 2015</strong><br>
	Our LiSense got accepted by <strong><a href="http://www.sigmobile.org/mobicom/2015/program.html">MobiCom'15</a></strong></p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>May 21st 2015</strong><br>
	Our HiLight got <font color="red">Best Demo Award</font> by <strong><a href="http://www.sigmobile.org/mobisys/2015/program.php">MobiSys'15</a></strong></p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>May 18th 2015</strong><br>
	Our WiScan got accepted by <strong><a href="http://ubicomp.org/ubicomp2015/">UbiComp'15</a></strong></p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Feb. 13th 2015</strong><br>
	Our HiLight got accepted by <strong><a href="http://www.sigmobile.org/mobisys/2015/accepted.php">MobiSys'15</a></strong></p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Sept. 11th 2014</strong><br>
	Our HiLight won <font color="red">Best Paper Award</font> by <strong><a href="http://archive.networks.rice.edu/VLCS-2014/">VLCS'14</a></strong></p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Sept. 11th 2014</strong><br>
	I won <font color="red">Bronze Medal</font> of Student Research Competition at <strong><a href="http://www.sigmobile.org/mobicom/2014/">MobiCom'14</a></strong></p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Sept. 9th 2014</strong><br>
	Our StudentLife won <font color="red">Best Paper Nominee</font> by <strong><a href="http://ubicomp.org/ubicomp2014/attending/best-papers.php">UbiComp'14</a></strong></p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Jun. 15th 2014</strong><br>
	Our HiLight got accepted by <strong><a href="http://archive.networks.rice.edu/VLCS-2014/program.html">VLCS'14</a></strong></p>
<p><img src="./Tianxing Li&#39;s Website_files/pushpin.jpg" width="10"> <strong>Mar. 5th 2014</strong><br>
	Our StudentLife got accepted by <strong><a href="http://ubicomp.org/ubicomp2014/attending/program-papers.php">UbiComp'14</a></strong></p>
</ul>

</ul></div>
<div id="text">

<p>I am a Ph.D. candidate in the <a href="http://www.cs.dartmouth.edu/">Computer Science Department</a> at <a href="http://www.dartmouth.edu/">Dartmouth College</a>. I am currently working in the <a href="http://dartnets.cs.dartmouth.edu/">DartNets Lab</a> under the supervision of Prof. <a href="http://www.cs.dartmouth.edu/~xia/">Xia Zhou</a>.</p>
        <p>My research interests are in wireless communication, sensing, and low-power systems. My work on light-based sensing won MobiCom Best Video Award in 2015, and was selected as a Best Paper Nominee at SenSys 2017, SIGMOBILE Research Highlights in 2016 and 2018, and CACM Research Highlights in 2018. I has also received MobiSys Best Demo Award in 2015, VLCS Best Paper Award in 2014, and UbiComp Best Paper Nominee Award in 2014.</p>
<a name="publications"></a>
        <p>I earned my M.S. at <a href="http://www.dartmouth.edu/">Dartmouth College</a> in 2014 and B.E. with honor from <a href="https://www.anu.edu.au/">Australian National University</a> in 2012.</p>
        
        <p><strong>I am in the job market, looking for academic position.</strong></p>

<hr>
<h1>Publications</h1>
<p>*H-index = <font color="#FF0000">8</font>, Citation = <font color="#FF0000">893</font> according to <a href="http://scholar.google.com/citations?user=fsnA2skAAAAJ&amp;hl=en">Google Scholar.</a></p>
<h3>Conference and Workshop</h3>
<ul>
<li>
			<p><strong>Battery-Free Eye Tracker on Glasses</strong><br>
			<strong>Tianxing Li</strong> and Xia Zhou, <br>
            Proceedings of <em>the 24th Annual International Conference on Mobile Computing and Networking (<strong>MobiCom 2018</strong>)</em><br>
            New Delhi, India, Nov. 2018.<br>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/eye.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a>&nbsp;<a href="https://youtu.be/b5AGVpQefss" class="btn btn-primary btn-xs"><font color="white">Video</font></a>&nbsp; <a href="https://www.cs.dartmouth.edu/~ltx/slides/mobicom18.pptx" class="btn btn-primary btn-xs"><font color="white">Slides</font></a>&nbsp;</p>
        	</li>
<li>
			<p><strong>Self-Powered Gesture Recognition with Ambient Light</strong><br>
			Yichen Li*, <strong>Tianxing Li*</strong>, Ruchir A. Patel, Xing-Dong Yang, and Xia Zhou, (* co-primary)<br>
            Proceedings of <em>the 31st ACM User Interface Software and Technology Symposium (<strong>UIST 2018</strong>)</em><br>
            Berlin, Germany, Oct. 2018.<br>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/uist18.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a>&nbsp;<a href="https://youtu.be/GeSoc9CrvVY" class="btn btn-primary btn-xs"><font color="white">Video</font></a>
        	</p></li>
<li>
			<p><strong>Ultra-Low Power Gaze Tracking for Virtual Reality</strong><br>
			<strong>Tianxing Li</strong>, Qiang Liu, and Xia Zhou, <br>
            Proceedings of <em>the 15th ACM Conference on Embedded Networked Sensor Systems (<strong>Sensys 2017</strong>)</em><br>
            Delft, The Netherlands, Nov. 2017.<br>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/gaze.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a>&nbsp;<a href="https://www.youtube.com/watch?v=l_AkoQNGkGw&amp;feature=youtu.be" class="btn btn-primary btn-xs"><font color="white">Video</font></a>&nbsp; <a href="https://www.cs.dartmouth.edu/~ltx/slides/sensys17.pptx" class="btn btn-primary btn-xs"><font color="white">Slides</font></a>&nbsp;<a href="http://dartnets.cs.dartmouth.edu/ligaze" class="btn btn-primary btn-xs"><font color="white">Project Website</font></a>&nbsp;<span class="label label-danger">Best Paper Nominee</span>&nbsp;<span class="label label-danger">SIGMOBILE Research Highlights Award</span>&nbsp;<span class="label label-danger">CACM Research Highlights Award</span></p>
        	</li>
<li>
			<p><strong>Reconstructing Hand Poses Using Visible Light</strong><br>
			<strong>Tianxing Li*</strong>, Xi Xiong*, Yifei Xie, George Hito, Xing-Dong Yang, and Xia Zhou, (* co-primary)<br>
            Proceedings of the 2017 <em>ACM International Joint Conference on Pervasive and Ubiquitous Computing (<strong>UbiComp 2017</strong>)</em><br>
            Maui, Hawaii, Sept. 2017.<br>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/lamp_ubicomp.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a>&nbsp;<a href="https://youtu.be/Fl1vVc3UGLA" class="btn btn-primary btn-xs"><font color="white">Video</font></a>&nbsp; <a href="https://www.cs.dartmouth.edu/~ltx/slides/ubicomp2017.pptx" class="btn btn-primary btn-xs"><font color="white">Slides</font></a>&nbsp;<a href="http://dartnets.cs.dartmouth.edu/aili" class="btn btn-primary btn-xs"><font color="white">Project Website</font></a></p>
        	</li>
<li>
			<p><strong>Practical Human Sensing in the Light</strong><br>
			<strong>Tianxing Li</strong>, Qiang Liu, and Xia Zhou, <br>
            Proceedings of <em>the 14th International Conference on Mobile Systems, Applications, and Services (<strong>MobiSys 2016</strong>)</em><br>
            Singapore, June. 2016.<br>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/sys116-liA.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a>&nbsp;<a href="https://www.youtube.com/watch?v=DIDxR4zdrds" class="btn btn-primary btn-xs"><font color="white">Video</font></a>&nbsp;<a href="https://www.cs.dartmouth.edu/~ltx/slides/mobisys16.pptx" class="btn btn-primary btn-xs"><font color="white">Slides</font></a>&nbsp; <a href="http://dartnets.cs.dartmouth.edu/starlight" class="btn btn-primary btn-xs"><font color="white">Project Website</font></a>&nbsp;<span class="label label-danger">SIGMOBILE Research Highlights Award</span></p>
        	</li>
<li>            
          	<p><strong>Human Sensing Using Visible Light Communication</strong><br>
			<strong>Tianxing Li</strong>, Chuankai An, Zhao Tian, Andrew T. Campbell, and Xia Zhou, <br>
            Proceedings of <em>the 21st Annual International Conference on Mobile Computing and Networking (<strong>MobiCom 2015</strong>)</em><br>
            Paris, France, Sept. 2015.<br>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/mobicom15-li.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a>&nbsp;<a href="https://www.youtube.com/watch?v=7wK-zo66GdY" class="btn btn-primary btn-xs"><font color="white">Video</font></a>&nbsp; <a href="https://www.cs.dartmouth.edu/~ltx/slides/lisense-mobicom15.pptx" class="btn btn-primary btn-xs"><font color="white">Slides</font></a>&nbsp;<a href="http://dartnets.cs.dartmouth.edu/lisense" class="btn btn-primary btn-xs"><font color="white">Project Website</font></a> &nbsp;<span class="label label-danger">Best Video Award</span></p>
        	</li>
<li>
          	<p><strong>Visible Light Knows Who You Are</strong><br>
			Chuankai An, <strong>Tianxing Li</strong>, Zhao Tian, Andrew T. Campbell, and Xia Zhou, <br>
            Proceedings of <em>the 2nd ACM Workshop on VLC systems (<strong>VLCS 2015</strong>)</em><br>
            Paris, France, Sept. 2015.<br>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/vlcs15.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a></p>
        	</li>
<li>
          	<p><strong>Low-Power Pervasive Wi-Fi Connectivity Using WiScan</strong><br>
			<strong>Tianxing Li</strong>, Chuankai An, Ranveer Chandra, Andrew T. Campbell, and Xia Zhou, <br>
            Proceedings of the 2015 <em>ACM International Joint Conference on Pervasive and Ubiquitous Computing (<strong>UbiComp 2015</strong>)</em><br>
            Osaka, Japan, Sept. 2015.<br>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/ubicomp15-li.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a>&nbsp;<a href="https://www.cs.dartmouth.edu/~ltx/slides/ubicomp15-li.pptx" class="btn btn-primary btn-xs"><font color="white">Slides</font></a>
        	</p></li>
<li>
          	<p><strong>Real-time Screen-camera Communication Behind Any Scene</strong><br>
			<strong>Tianxing Li</strong>, Chuankai An, Xinran Xiao, Andrew T. Campbell, and Xia Zhou, <br>
            Proceedings of <em>the 13th International Conference on Mobile Systems, Applications, and Services (<strong>MobiSys 2015</strong>)</em><br>
            Florence, Italy, May 2015.<br>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/mobisys15li.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a>&nbsp;<a href="https://www.youtube.com/watch?v=VbG4VNA7RZs" class="btn btn-primary btn-xs"><font color="white">Video</font></a>&nbsp;<a href="https://www.cs.dartmouth.edu/~ltx/slides/hilight-mobisys15.pptx" class="btn btn-primary btn-xs"><font color="white">Slides</font></a>&nbsp;<a href="https://github.com/Tianxing-Dartmouth/HiLight" class="btn btn-primary btn-xs"><font color="white">Code</font></a>&nbsp; <a href="http://dartnets.cs.dartmouth.edu/hilight" class="btn btn-primary btn-xs"><font color="white">Project Website</font></a>&nbsp;<span class="label label-danger">Best Demo Award</span></p>
        	</li>
<li>
          	<p><strong>HiLight: Hiding Bits In Pixel Translucency Changes</strong><br>
			<strong>Tianxing Li</strong>, Chuankai An, Andrew T. Campbell, and Xia Zhou, <br>
            Proceedings of <em>the 1st ACM Workshop on VLC systems (<strong>VLCS 2014</strong>)</em><br>
            Maui, Hawaii, Sept. 2014.<br>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/vlcs14-tianxing.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a>
		&nbsp;<a href="https://www.cs.dartmouth.edu/~ltx/slides/Mobicom14_workshop_presentation.pptx" class="btn btn-primary btn-xs"><font color="white">Slides</font></a>&nbsp;<span class="label label-danger">Best Paper Award</span></p>
        	</li>
<li>
          	<p><strong>StudentLife: Assessing Mental Health, Academic Performance And Behavioral Trends Of College Students Using Smartphones</strong><br>
			Rui Wang, Fanglin Chen, Zhenyu Chen, <strong>Tianxing Li</strong>, Gabriella Harari, Stefanie Tigno, Xia Zhou, Dror Ben-Zeev, and Andrew T. Campbell, <br>
            Proceedings of the 2014 <em>ACM International Joint Conference on Pervasive and Ubiquitous Computing (<strong>UbiComp 2014</strong>)</em><br>
			Seattle, Sept. 2014.<br>
            <a href="http://studentlife.cs.dartmouth.edu/studentlife.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a>&nbsp; <a href="http://studentlife.cs.dartmouth.edu/" class="btn btn-primary btn-xs"><font color="white">Project Website</font></a>
		&nbsp;<span class="label label-danger">Best Paper Nominee</span></p><p></p>
        	</li>
<li>
          	<p><strong>Unobtrusive Sleep Monitoring Using Smartphones</strong><br>
			Zhenyu Chen, Mu Lin, Fanglin Chen, Lane, N.D., Cardone, G.,Rui Wang, <strong>Tianxing Li</strong>, Yiqiang Chen, Choudhury, T. Campbell, A.T., <br>
            Proceedings of <em>the 7th International Conference on Pervasive Computing Technologies for Healthcare (<strong>Pervasive Health 2013</strong>)</em><br>
            Venice, Italy, May 2013.<br>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/Unobtrusive%20Sleep%20Monitoring%20using%20Smartphones.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a></p>
        	</li>
<li>
          	<p><strong>Dual Deblurring Leveraged By Image Matching</strong><br>
			Fang Wang, <strong>Tianxing Li</strong>, Yi Li, <br>
            Proceedings of the 2013 <em>IEEE International Conference on Image Processing (<strong>ICIP 2013</strong>)</em><br>
            Melbourne, Australia, Sept. 2013.<br>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/Dual%20deblurring%20leveraged%20by%20image%20matching.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a></p>
        	</li>

<h3>Demos and Posters</h3>
<ul>
<li>
          	<p><strong>Demo: Ultra-Low Power Gaze Tracking for Virtual Reality</strong><br>
			<strong>Tianxing Li</strong>, Emmanuel S. Akosah, Qiang Liu, and Xia Zhou, <br>
            Proceedings of <em>the 15th ACM Conference on Embedded Networked Sensor Systems (<strong>SenSys 2017</strong>)</em><br>
            Delft, The Netherlands, Nov. 2017.<br>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/sensys17demo.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a>
				</p>
        	</li>
<li>
          	<p><strong>Demo: Real-Time Screen-Camera Communication Behind Any Scene</strong><br>
			<strong>Tianxing Li</strong>, Chuankai An, Xinran Xiao, Andrew T. Campbell, and Xia Zhou, <br>
            Proceedings of <em>the 13th International Conference on Mobile Systems, Applications, and Services (<strong>MobiSys 2015</strong>)</em><br>
            Florence, Italy, May 2015.<br>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/p455-li.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a>
				&nbsp;<span class="label label-danger">Best Demo Award</span></p>
        	</li>

<li>
          	<p><strong>Poster: HiLight: Hiding Bits In Pixel Translucency Changes</strong><br>
			<strong>Tianxing Li</strong>, Chuankai An, Andrew T. Campbell, and Xia Zhou, <br>
            Proceedings of <em>the 20st Annual International Conference on Mobile Computing and Networking (<strong>MobiCom 2014</strong>)</em><br>
            Maui, Hawaii, Sept. 2014.<br>
<a name="research"></a>
            <a href="https://www.cs.dartmouth.edu/~ltx/paper/p383-li.pdf" class="btn btn-primary btn-xs"><font color="white">PDF</font></a>
				&nbsp;<span class="label label-danger">Student Research Competition Bronze Medal</span></p>
        	</li>
<hr width="130%">
<h1>Research</h1>
<div class="mydiv">
        <iframe class="myimage" src="./Tianxing Li&#39;s Website_files/b5AGVpQefss.html" frameborder="0" allowfullscreen=""> </iframe>

        <h4>Battery-Free Eye Tracker on Glasses</h4>
                        <div class="row">
                            <ul class="list right">
<p>We presents a battery-free wearable eye tracker that tracks both the 2D position and diameter of a pupil based on its light absorption property. With a few near-infrared (NIR) lights and photodiodes around the eye, NIR lights sequentially illuminate the eye from various directions while photodiodes sense spatial patterns of reflected light, which are used to infer pupil’s position and diameter on the fly via a lightweight inference algorithm. The system also exploits characteristics of different eye movement stages and adjusts its sensing and computation accordingly for further energy savings. A prototype is built with off-the-shelf hardware components and integrated into a regular pair of glasses. This work will present in MobiCom'18. <a href="https://www.cs.dartmouth.edu/~ltx/paper/eye.pdf">[PDF]</a></p>
                                <p><em> Experiments with 22 participants show that the system achieves 0.8-mm mean error in tracking pupil position (2.3 mm at the 95th percentile) and 0.3-mm mean error in tracking pupil diameter (0.9 mm at the 95th percentile) at 120-Hz output frame rate, consuming 395μW mean power supplied by two small, thin solar cells on glasses side arms. </em></p>
                            </ul>
                        </div>

    </div>
<div class="mydiv">

        <iframe class="myimage" src="./Tianxing Li&#39;s Website_files/GeSoc9CrvVY.html" frameborder="0" allowfullscreen=""> </iframe>

        <h4>Self-Powered Gesture Recognition with Ambient Light</h4>
                        <div class="row">
                            <ul class="list right">
<p>We present a self-powered module for gesture recognition that utilizes small, low-cost photodiodes for both energy harvesting and gesture sensing. Operating in the photovoltaic mode, photodiodes harvest energy from ambient light. In the meantime, the instantaneously harvested power from individual photodiodes is monitored and exploited as a clue for sensing finger gestures in proximity. Harvested power from all photodiodes are aggregated to drive the whole gesture-recognition module including a micro-controller running the recognition algorithm. We design robust, lightweight algorithm to recognize finger gestures in the presence of ambient light fluctuations. We fabricate two prototypes to facilitate user’s interaction with smart glasses and smart watches. This work will present in UIST'18. <a href="https://www.cs.dartmouth.edu/~ltx/paper/uist18.pdf">[PDF]</a></p>
                                <p><em> Results show 99.7%/98.3% overall precision/recall in recognizing five gestures on glasses and 99.2%/97.5% precision/recall in recognizing seven gestures on the watch. The system consumes 34.6 µW/74.3 µW for the glasses/watch and thus can be powered by the energy harvested from ambient light. </em></p>
                            </ul>
                        </div>

    </div>
<div class="mydiv">

        <iframe class="myimage" src="./Tianxing Li&#39;s Website_files/l_AkoQNGkGw.html" frameborder="0" allowfullscreen=""> </iframe>

        <h3><a href="http://dartnets.cs.dartmouth.edu/ligaze">LiGaze</a></h3> 
        <h4>Ultra-Low Power Gaze Tracking for Virtual Reality</h4>
                        <div class="row">
                            <ul class="list right">
<p>We present LiGaze, a low-cost, low-power approach to gaze tracking tailored to VR. It relies on a few low-cost photodiodes, eliminating the need for cameras and active infrared emitters. Reusing light emitted from the VR screen, LiGaze leverages photodiodes around a VR lens to measure reflected screen light in different directions. It then infers gaze direction by exploiting pupil’s light absorption property. The core of LiGaze is to deal with screen light dynamics and extract changes in reflected light related to pupil movement. LiGaze infers a 3D gaze vector on the fly using a lightweight regression algorithm. We design and fabricate a LiGaze prototype using off-the-shelf photodiodes. LiGaze’s simplicity and ultra-low power make it applicable in a wide range of VR headsets to better unleash VR’s potential. This work presented in SenSys'17 and won Best Paper Nominee. <a href="https://www.cs.dartmouth.edu/~ltx/paper/lamp_ubicomp.pdf">[PDF]</a><a href="http://dartnets.cs.dartmouth.edu/ligaze">[PROJECT WEBSITE]</a></p>
                                <p><em> LiGaze achieves 6.3° and 10.1° mean within-user and cross-user accuracy. Its sensing and computation consume 791µW in total and thus can be completely powered by a credit-card sized solar cell harvesting energy from indoor lighting. </em></p>
                            </ul>
                        </div>

    </div>
<div class="mydiv">

        <iframe class="myimage" src="./Tianxing Li&#39;s Website_files/Fl1vVc3UGLA.html" frameborder="0" allowfullscreen=""> </iframe>

        <h3><a href="http://dartnets.cs.dartmouth.edu/aili">Aili</a></h3> 
        <h4>Reconstructing Hand Poses Using Visible Light</h4>
                        <div class="row">
                            <ul class="list right">
<p>Free-hand gestural input is essential for emerging user interactions. We present Aili, a table lamp reconstructing a 3D hand skeleton in real time, requiring neither cameras nor on-body sensing devices. Aili consists of an LED panel in a lampshade and a few low-cost photodiodes embedded in the lamp base. To reconstruct a hand skeleton, Aili combines 2D binary blockage maps from vantage points of dierent photodiodes, which describe whether a hand blocks light rays from individual LEDs to all photodiodes. Empowering a table lamp with sensing capability, Aili can be seamlessly integrated into the existing environment. Relying on such low-level cues, Aili entails lightweight computation and is inherently privacy-preserving. We build and evaluate an Aili prototype. We also conduct user studies to examine the privacy issues of Leap Motion and solicit feedback on Aili’s privacy protection. We conclude by demonstrating various interaction applications Aili enables. This work presented in UbiComp'17. <a href="https://www.cs.dartmouth.edu/~ltx/paper/lamp_ubicomp.pdf">[PDF]</a><a href="http://dartnets.cs.dartmouth.edu/aili">[PROJECT WEBSITE]</a></p>
                                <p><em> Aili achieves 10.2° mean angular deviation and 2.5-mm mean translation deviation in comparison to Leap Motion.</em></p>
                            </ul>
                        </div>

    </div>
<div class="mydiv">

        <iframe class="myimage" src="./Tianxing Li&#39;s Website_files/DIDxR4zdrds.html" frameborder="0" allowfullscreen=""> </iframe>

        <h3><a href="http://dartnets.cs.dartmouth.edu/starlight">StarLight</a></h3> 
        <h4>Human Sensing Using VLC</h4>
                        <div class="row">
                            <ul class="list right">
<p>We present StarLight, an infrastructure-based sensing system that reuses light emitted from ceiling LED panels to reconstruct fine-grained user skeleton postures continuously in real time. It relies on only a few (e.g., 20) photodiodes placed at optimized locations to passively capture low-level visual clues (light blockage information), with neither cameras capturing sensitive images, nor on-body devices, nor electromagnetic interference. It then aggregates the blockage information of a large number of light rays from LED panels and identifies best-fit 3D skeleton postures. StarLight greatly advances the prior light-based sensing design by dramatically reducing the number of intrusive sensors, overcoming furniture blockage, and supporting user mobility. We build and deploy StarLight in a 3.6 m x 4.8 m office room, with customized 20 LED panels and 20 photodiodes. This work presented at MobiSys'16 and won SIGMOBILE Research Highlights Award. <a href="https://www.cs.dartmouth.edu/~ltx/paper/sys116-liA.pdf">[PDF]</a><a href="http://dartnets.cs.dartmouth.edu/starlight">[PROJECT WEBSITE]</a></p>
                                <p><em> StarLight achieves 13.6° mean angular error for five body joints and reconstructs a mobile skeleton at 40 FPS frame rate.</em></p>
                            </ul>
                        </div>

    </div>
<div class="mydiv">

        <iframe class="myimage" src="./Tianxing Li&#39;s Website_files/7wK-zo66GdY.html" frameborder="0" allowfullscreen=""> </iframe>

        <h3><a href="http://dartnets.cs.dartmouth.edu/lisense">LiSense</a></h3> 
        <h4>Human Sensing Using VLC</h4>
                        <div class="row">
                            <ul class="list right">
<p>LiSense is the first-of-kind system that enables both data communication and fine-grained, real-time human skeleton reconstruction using Visible Light Communication. LiSense uses shadows created by the human body from blocked light and reconstructs 3D human skeleton postures in real time. Multiple lights on the ceiling lead to diminished and complex shadow patterns on the floor. We design light beacons to separate light rays from different light sources and recover the shadow pattern cast by each individual light. Then, we design an efficient inference algorithm to reconstruct user postures using 2D shadows with a limited resolution collected by photodiodes. This work was presented in MobiCom'15 won the <em>Best Video Award</em>. <a href="https://www.cs.dartmouth.edu/~ltx/paper/mobicom15-li.pdf">[PDF]</a><a href="http://dartnets.cs.dartmouth.edu/lisense">[PROJECT WEBSITE]</a></p>
                                <p><em> LiSense reconstructs the 3D user skeleton at 60 Hz in real time with 10° mean angular error for five body joints.</em></p>
                            </ul>
                        </div>

    </div>
    <!-- <p>&nbsp;</p> -->
    <div class="mydiv">

        <img class="myimage" src="./Tianxing Li&#39;s Website_files/wiscan.jpg">

        <h3>WiScan</h3>
        <h4>Low-Power Pervasive Wi-Fi Connectivity</h4>
        <div class="row">
                            <ul class="list right">
<p>Pervasive Wi-Fi connectivity is attractive for users in places not covered by cellular services (e.g., when traveling abroad). However, the power drain of frequent Wi-Fi scans undermines the device's battery life, preventing users from staying always connected and fetching synced emails and instant message notifications. We study the energy overhead of scan and roaming in detail and refer to it as the scan tax problem. Our findings show that the main processor is the primary culprit of the energy overhead.  We design and build WiScan to fully exploit the gain of scan offloading. This work was presented in UbiComp'15. <a href="https://www.cs.dartmouth.edu/~ltx/paper/ubicomp15-li.pdf">[PDF]</a></p>
                                <p><em> WiScan achieves 90%+ of the maximal connectivity, while saving 50-62% energy for seeking connectivity.</em></p>
                            </ul>
                        </div>

    </div>
    <!-- <p>&nbsp;</p> -->
    <div class="mydiv">

        <iframe class="myimage" src="./Tianxing Li&#39;s Website_files/VbG4VNA7RZs.html" frameborder="0" allowfullscreen=""> </iframe>

        <h3><a href="http://dartnets.cs.dartmouth.edu/hilight">HiLight</a></h3>
                        <h4>Real-Time Screen-Camera Communication Behind Any Scene</h4>
                        <div class="row">
                            <ul class="list right">
<p> HiLight is a new form of real-time screen-camera communication without showing any coded images (e.g., barcodes) for off-the-shelf smart devices. HiLight encodes data into pixel translucency change atop any screen content, so that camera-equipped devices can fetch the data by turning their cameras to the screen. HiLight leverages the alpha channel, a well-known concept in computer graphics, to encode bits into the pixel translucency change. By removing the need to directly modify pixel RGB values, HiLight overcomes the key bottleneck of existing designs and enables real-time unobtrusive communication while supporting any screen content. This work was presented in MobiSys'15 and won the <em>Best Demo Award</em>. <a href="https://www.cs.dartmouth.edu/~ltx/paper/li2015real.pdf">[PDF]</a><a href="https://github.com/Tianxing-Dartmouth/HiLight">[CODE]</a><a href="http://dartnets.cs.dartmouth.edu/hilight">[PROJECT WEBSITE]</a></p>
                                <p><em> We design and build HiLight using off-the-shelf smart devices, the first system that realizes on-demand data transmissions in real time unobtrusively atop arbitrary screen content.</em></p>
                            </ul>
                        </div>

    </div>
<div class="mydiv">

        <img class="myimage" src="./Tianxing Li&#39;s Website_files/studentlife.jpg">

        <h3><a href="http://studentlife.cs.dartmouth.edu/">StudentLife</a></h3>
                        <h4>Assessing Mental Health, Academic Performance and Behavioral Trends of College Students using Smartphones</h4>
                        <div class="row">
                            <ul class="list right">
<p>The StudentLife continuous sensing app assesses the day-to-day and week-by-week impact of workload on stress, sleep, activity, mood, sociability, mental well-being and academic performance of a single class of 48 students across a 10-week term at Dartmouth College using Android phones. This work was presented in UbiComp'14 and won the <em>Best Paper Nominee Award</em>. <a href="http://studentlife.cs.dartmouth.edu/studentlife.pdf">[PDF]</a><a href="http://studentlife.cs.dartmouth.edu/">[PROJECT WEBSITE]</a></p>
                                <p><em>The StudentLife study shows a number of significant correlations between the automatic objective sensor data from smartphones and mental health and educational outcomes of the student body.</em></p>
                            </ul>
                        </div>

    </div>
</ul></ul></div>


<!-- end main -->
<!-- footer -->

<div id="footer">
<p>Last updated April 5th 2019.
	                You are the
	  			  <!-- Start of StatCounter Code for Default Guide -->
	  			  <script type="text/javascript">
	  			  var sc_project=9897330; 
	  			  var sc_invisible=0; 
	  			  var sc_security="4709a146"; 
	  			  var scJsHost = (("https:" == document.location.protocol) ?
	  			  "https://secure." : "http://www.");
	  			  document.write("<sc"+"ript type='text/javascript' src='" +
	  			  scJsHost+
	  			  "statcounter.com/counter/counter.js'></"+"script>");
	  			  </script><script type="text/javascript" src="./Tianxing Li&#39;s Website_files/counter.js"></script><span class="statcounter"><a class="statcounter" href="http://www.statcounter.com/" target="_blank"><img src="./Tianxing Li&#39;s Website_files/t.php" alt="StatCounter - Free Web Tracker and Counter" border="0"></a></span>

	  			  <noscript><div class="statcounter"><a title="web analytics"
	  			  href="http://statcounter.com/" target="_blank"><img
	  			  class="statcounter"
	  			  src="http://c.statcounter.com/9897330/0/4709a146/0/"
	  			  alt="web analytics"></a></div></noscript>
	  			  <!-- End of StatCounter Code for Default Guide -->
	                th visitor.</p>
</div>
</div>
<!-- end footer -->
</div>

</body></html>